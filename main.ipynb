{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7081e24",
   "metadata": {},
   "source": [
    "## Monte Carlo simulation with fixed investment rate\n",
    "Static approach being simple but significantly worse than dynamic investment rate setting, blah blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913bcd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cbd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e5ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "capital_per_turn = []\n",
    "data = []\n",
    "simulation_num = 10000\n",
    "percentage_to_bet = 0.23\n",
    "loss_counter = 0\n",
    "\n",
    "for k in range(simulation_num):\n",
    "    capital = 100\n",
    "    turn_num = 0\n",
    "    \n",
    "    for x in range(100):\n",
    "        if capital == 0:\n",
    "            loss_counter += 1\n",
    "            break        \n",
    "\n",
    "        turn_num += 1\n",
    "\n",
    "        randint = random.randint(1, 10)\n",
    "\n",
    "        if randint >= 5:  # Win (60%)\n",
    "            capital *= (1 + percentage_to_bet)\n",
    "        else:  # Lose (40%)\n",
    "            capital *= (1 - percentage_to_bet)\n",
    "        \n",
    "        capital_per_turn.append(capital)\n",
    "    data.append(capital_per_turn[-1])\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b252865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss counter: 0\n",
      "                  0\n",
      "count  1.000000e+04\n",
      "mean   8.680529e+03\n",
      "std    4.881285e+04\n",
      "min    2.392320e-02\n",
      "25%    1.752639e+02\n",
      "50%    7.143905e+02\n",
      "75%    2.911916e+03\n",
      "max    2.051069e+06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Loss counter: {loss_counter}\")\n",
    "print(df.describe())\n",
    "\n",
    "# print(df.info())\n",
    "sns.histplot(df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1dbb33",
   "metadata": {},
   "source": [
    "## Reinforced Learning approach\n",
    "Dynamic approach better than static, blah blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00a5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e45923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class InvestmentEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Gymnasium environment for the investment game.\n",
    "    \n",
    "    State Space:\n",
    "        - Current capital (continuous)\n",
    "        - Current round number (0-99)\n",
    "    \n",
    "    Action Space:\n",
    "        - Investment percentage (continuous, 0.0 to 1.0)\n",
    "    \n",
    "    Rewards:\n",
    "        - Based on capital change each round\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initial_capital=100, num_rounds=100, win_probability=0.6):\n",
    "        super(InvestmentEnv, self).__init__()\n",
    "        \n",
    "        # Game parameters\n",
    "        self.initial_capital = initial_capital\n",
    "        self.num_rounds = num_rounds\n",
    "        self.win_probability = win_probability\n",
    "        \n",
    "        # Define action space: investment percentage between 0% and 100%\n",
    "        self.action_space = spaces.Box(\n",
    "            low=0.0, \n",
    "            high=1.0, \n",
    "            shape=(1,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Define observation space: [capital, round_number]\n",
    "        # Capital can theoretically grow unbounded, but we'll set a reasonable upper limit\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0, 0], dtype=np.float32),\n",
    "            high=np.array([1e10, num_rounds], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Initialise state\n",
    "        self.capital = None\n",
    "        self.current_round = None\n",
    "        self.np_random = None\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        Reset the environment to initial state.\n",
    "        Called at the start of each episode.\n",
    "        \"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        self.capital = float(self.initial_capital)\n",
    "        self.current_round = 0\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        info = {}\n",
    "        \n",
    "        return observation, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Execute one round of the game.\"\"\"\n",
    "        old_capital = self.capital\n",
    "        \n",
    "        investment_percentage = np.clip(action[0], 0.0, 1.0)\n",
    "        investment_amount = self.capital * investment_percentage\n",
    "        \n",
    "        outcome = self.np_random.random()\n",
    "        \n",
    "        if outcome < self.win_probability:\n",
    "            self.capital += investment_amount\n",
    "        else:\n",
    "            self.capital -= investment_amount\n",
    "        \n",
    "        if self.capital < 0:\n",
    "            self.capital = 0\n",
    "        \n",
    "        self.current_round += 1\n",
    "        terminated = (self.current_round >= self.num_rounds) or (self.capital == 0)\n",
    "        truncated = False\n",
    "        \n",
    "        # REWARD WITH STAGNANCY PENALTY\n",
    "        if terminated:\n",
    "            if self.capital > 0:\n",
    "                # Reward based on total growth\n",
    "                reward = np.log(self.capital / self.initial_capital) * 10\n",
    "            else:\n",
    "                reward = -50  # Bankruptcy penalty\n",
    "        else:\n",
    "            # Intermediate reward\n",
    "            capital_change = self.capital - old_capital\n",
    "            reward = capital_change / self.initial_capital\n",
    "            \n",
    "            # STAGNANCY PENALTY: Punish low investment percentages\n",
    "            if investment_percentage < 0.05:  # Less than 5% investment\n",
    "                reward -= 0.5  # Penalty for being too conservative\n",
    "            \n",
    "            # BONUS: Reward for taking reasonable risks\n",
    "            if 0.15 <= investment_percentage <= 0.40:\n",
    "                reward += 0.1  # Small bonus for \"reasonable\" investment range\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        info = {\n",
    "            'capital': self.capital,\n",
    "            'round': self.current_round,\n",
    "            'investment_percentage': investment_percentage,\n",
    "            'won': outcome < self.win_probability\n",
    "        }\n",
    "        \n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"Return the current state observation.\"\"\"\n",
    "        return np.array([self.capital, self.current_round], dtype=np.float32)\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Optional: print current state (useful for debugging).\"\"\"\n",
    "        print(f\"Round {self.current_round}/{self.num_rounds} | Capital: ${self.capital:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c97de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: Capital=$100.00, Round=0.0\n",
      "Round 1: Invested 47.7% | LOST | Capital: $52.26\n",
      "Round 2: Invested 71.6% | WON | Capital: $89.68\n",
      "Round 3: Invested 10.0% | LOST | Capital: $80.74\n",
      "Round 4: Invested 22.4% | LOST | Capital: $62.66\n",
      "Round 5: Invested 53.9% | WON | Capital: $96.43\n"
     ]
    }
   ],
   "source": [
    "# Create environment\n",
    "env = InvestmentEnv()\n",
    "\n",
    "# Test one episode with random actions\n",
    "observation, info = env.reset(seed=42)\n",
    "print(f\"Initial state: Capital=${observation[0]:.2f}, Round={observation[1]}\")\n",
    "\n",
    "for i in range(5):  # Just test 5 rounds\n",
    "    # Random action (random investment percentage)\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    print(f\"Round {info['round']}: Invested {info['investment_percentage']*100:.1f}% | \"\n",
    "          f\"{'WON' if info['won'] else 'LOST'} | Capital: ${info['capital']:.2f}\")\n",
    "    \n",
    "    if terminated:\n",
    "        print(\"Episode ended!\")\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eef406",
   "metadata": {},
   "source": [
    "## RL Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012c251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Starting training...\n",
      "==================================================\n",
      "Logging to ./ppo_investment_tensorboard/PPO_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">a:\\Repositories\\Investing-simulation\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "a:\\Repositories\\Investing-simulation\\.venv\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 15       |\n",
      "|    ep_rew_mean     | 237      |\n",
      "| time/              |          |\n",
      "|    fps             | 2003     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.8         |\n",
      "|    ep_rew_mean          | 24.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045879893 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 1.47e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000252    |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 6.9e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | -12.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 473          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039636116 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.00271      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.59e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 3.5e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 22.2         |\n",
      "|    ep_rew_mean          | -36.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 427          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013623077 |\n",
      "|    clip_fraction        | 0.00325      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 7.9e-05      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.04e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000243    |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 2.44e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">a:\\Repositories\\Investing-simulation\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:70: \n",
       "UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting \n",
       "modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first\n",
       "with ``Monitor`` wrapper.\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "a:\\Repositories\\Investing-simulation\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:70: \n",
       "UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting \n",
       "modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first\n",
       "with ``Monitor`` wrapper.\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=40000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=40000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015964541 |\n",
      "|    clip_fraction        | 0.000647     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00892      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | 0.000111     |\n",
      "|    std                  | 0.973        |\n",
      "|    value_loss           | 6.56e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.6     |\n",
      "|    ep_rew_mean     | -40.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 336      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 121      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.6         |\n",
      "|    ep_rew_mean          | -48.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032600902 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 923          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000676    |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 1.26e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 41.3         |\n",
      "|    ep_rew_mean          | -32          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074148234 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.00693      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 339          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    std                  | 0.951        |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 42           |\n",
      "|    ep_rew_mean          | -14.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012761689 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.000341     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 310          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 9.63e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.4         |\n",
      "|    ep_rew_mean          | -57.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031390644 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.00794      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.899        |\n",
      "|    value_loss           | 8.02e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=80000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=80000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 100         |\n",
      "|    mean_reward          | -49.5       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004123073 |\n",
      "|    clip_fraction        | 0.034       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.0142      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.6        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 56.3     |\n",
      "|    ep_rew_mean     | -17.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 325      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.6        |\n",
      "|    ep_rew_mean          | -37.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002128265 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.00662     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00064    |\n",
      "|    std                  | 0.87        |\n",
      "|    value_loss           | 8.28e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61.8         |\n",
      "|    ep_rew_mean          | -50.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 334          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023695831 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.0224       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000535    |\n",
      "|    std                  | 0.849        |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 64.8       |\n",
      "|    ep_rew_mean          | -50        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 330        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00222136 |\n",
      "|    clip_fraction        | 0.0272     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.0141     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.2e+03    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00133   |\n",
      "|    std                  | 0.843      |\n",
      "|    value_loss           | 1.58e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73           |\n",
      "|    ep_rew_mean          | -53.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 327          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 350          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023232962 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.0893       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000536    |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 404          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=120000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=120000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 100         |\n",
      "|    mean_reward          | -49.5       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001183343 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.000515   |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 81       |\n",
      "|    ep_rew_mean     | -29      |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 398      |\n",
      "|    total_timesteps | 122880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.8        |\n",
      "|    ep_rew_mean          | -45.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 430         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004365366 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.4        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000559   |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.2        |\n",
      "|    ep_rew_mean          | -49.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002887087 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000747   |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.4         |\n",
      "|    ep_rew_mean          | -46.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 322          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 456          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023823362 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 58.6         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000573    |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.8         |\n",
      "|    ep_rew_mean          | -54.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 468          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014083446 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -8.84e-05    |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=160000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=160000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024437753 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.835        |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 71.7     |\n",
      "|    ep_rew_mean     | -54.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 336      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 487      |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.4        |\n",
      "|    ep_rew_mean          | -51.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003314721 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 84.6         |\n",
      "|    ep_rew_mean          | -52          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 350          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 513          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022102185 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000684    |\n",
      "|    std                  | 0.819        |\n",
      "|    value_loss           | 55.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.9         |\n",
      "|    ep_rew_mean          | -52.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 355          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 529          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035608602 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36           |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    std                  | 0.815        |\n",
      "|    value_loss           | 74           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 89.8         |\n",
      "|    ep_rew_mean          | -52.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 544          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034478514 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | 4.29e-05     |\n",
      "|    std                  | 0.79         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=200000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=200000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032046065 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000815    |\n",
      "|    std                  | 0.782        |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 93.5     |\n",
      "|    ep_rew_mean     | -50.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 353      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 579      |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.4         |\n",
      "|    ep_rew_mean          | -49.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 616          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031606054 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | 0.00044      |\n",
      "|    std                  | 0.779        |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 90.7         |\n",
      "|    ep_rew_mean          | -47.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 641          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018329604 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.34         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | 0.0003       |\n",
      "|    std                  | 0.774        |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.4         |\n",
      "|    ep_rew_mean          | -44.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 350          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 654          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015936154 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000552    |\n",
      "|    std                  | 0.772        |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.8         |\n",
      "|    ep_rew_mean          | -48          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 355          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 668          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031272126 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.04         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000316    |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 9.04         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=240000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=240000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028695476 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000265    |\n",
      "|    std                  | 0.767        |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 92.5     |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 356      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 688      |\n",
      "|    total_timesteps | 245760   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 90.5         |\n",
      "|    ep_rew_mean          | -50.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 702          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033049656 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.44         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -5.53e-05    |\n",
      "|    std                  | 0.767        |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 90.8         |\n",
      "|    ep_rew_mean          | -51.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 365          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 716          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036692792 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.27         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000737    |\n",
      "|    std                  | 0.764        |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.5         |\n",
      "|    ep_rew_mean          | -47.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 730          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040079933 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    std                  | 0.759        |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 88.9         |\n",
      "|    ep_rew_mean          | -53.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 374          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 744          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019986476 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.869        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000226    |\n",
      "|    std                  | 0.758        |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=280000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=280000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 280000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034348504 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    std                  | 0.748        |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 92.9     |\n",
      "|    ep_rew_mean     | -51.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 375      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 762      |\n",
      "|    total_timesteps | 286720   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93           |\n",
      "|    ep_rew_mean          | -48.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 380          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 774          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024124677 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.79         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    std                  | 0.74         |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 97         |\n",
      "|    ep_rew_mean          | -48.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 385        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 786        |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00437386 |\n",
      "|    clip_fraction        | 0.0441     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.1        |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00222   |\n",
      "|    std                  | 0.728      |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.3         |\n",
      "|    ep_rew_mean          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 388          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 800          |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041775377 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.92         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -9.2e-05     |\n",
      "|    std                  | 0.726        |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | -49.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 814         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002766613 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.03        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000573   |\n",
      "|    std                  | 0.723       |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=320000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=320000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 100         |\n",
      "|    mean_reward          | -49.5       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004010042 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.68        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.000307   |\n",
      "|    std                  | 0.72        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 94.9     |\n",
      "|    ep_rew_mean     | -52.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 393      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 833      |\n",
      "|    total_timesteps | 327680   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.1        |\n",
      "|    ep_rew_mean          | -48.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002069818 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.000257   |\n",
      "|    std                  | 0.713       |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.2         |\n",
      "|    ep_rew_mean          | -47.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 400          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 858          |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025533224 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.22         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000396    |\n",
      "|    std                  | 0.707        |\n",
      "|    value_loss           | 16           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98.3         |\n",
      "|    ep_rew_mean          | -50.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 871          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021773502 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.82         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | 0.000167     |\n",
      "|    std                  | 0.709        |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=360000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=360000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 360000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026812013 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.8          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -7.84e-05    |\n",
      "|    std                  | 0.709        |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.2     |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 891      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96          |\n",
      "|    ep_rew_mean          | -46.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 904         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003032133 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.75        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.000549   |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.8         |\n",
      "|    ep_rew_mean          | -51          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 917          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023104514 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.56         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.000815    |\n",
      "|    std                  | 0.703        |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.3        |\n",
      "|    ep_rew_mean          | -51.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 930         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002550324 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.000117   |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 96.1         |\n",
      "|    ep_rew_mean          | -48.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 416          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 943          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027052027 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000488    |\n",
      "|    std                  | 0.689        |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=400000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=400000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032702032 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.85         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 0.000794     |\n",
      "|    std                  | 0.681        |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96       |\n",
      "|    ep_rew_mean     | -45.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 415      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 965      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 97.6         |\n",
      "|    ep_rew_mean          | -44.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 418          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 977          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036713053 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.61         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000737    |\n",
      "|    std                  | 0.674        |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 97.3         |\n",
      "|    ep_rew_mean          | -46.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 990          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037591625 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.22         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    std                  | 0.678        |\n",
      "|    value_loss           | 10.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 97           |\n",
      "|    ep_rew_mean          | -46.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 422          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 1008         |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022746543 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.34         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | 0.000191     |\n",
      "|    std                  | 0.676        |\n",
      "|    value_loss           | 12.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.3         |\n",
      "|    ep_rew_mean          | -51.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 4712         |\n",
      "|    total_timesteps      | 434176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032514902 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | 0.000733     |\n",
      "|    std                  | 0.677        |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=440000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=440000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 440000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049860436 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.89         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.000144    |\n",
      "|    std                  | 0.669        |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 94.1     |\n",
      "|    ep_rew_mean     | -49.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 92       |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 4764     |\n",
      "|    total_timesteps | 442368   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 96           |\n",
      "|    ep_rew_mean          | -51.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 94           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 4792         |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054567633 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | 8.09e-05     |\n",
      "|    std                  | 0.657        |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.4        |\n",
      "|    ep_rew_mean          | -48.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 4815        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004155404 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.998      |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.000432   |\n",
      "|    std                  | 0.661       |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.3         |\n",
      "|    ep_rew_mean          | -49.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 4839         |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046049263 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.91         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -8.89e-05    |\n",
      "|    std                  | 0.664        |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 97.7         |\n",
      "|    ep_rew_mean          | -47.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 4862         |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028255591 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.21         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -6.57e-05    |\n",
      "|    std                  | 0.651        |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=480000, episode_reward=-49.50 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=480000, episode_reward=-49.50 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 100.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 100.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 100          |\n",
      "|    mean_reward          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029257338 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.986       |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.97         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    std                  | 0.648        |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 94.7     |\n",
      "|    ep_rew_mean     | -46.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 98       |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 4899     |\n",
      "|    total_timesteps | 483328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.9        |\n",
      "|    ep_rew_mean          | -48.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 4922        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002663292 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00077    |\n",
      "|    std                  | 0.645       |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.5         |\n",
      "|    ep_rew_mean          | -47.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 4945         |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031281374 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.981       |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.000263    |\n",
      "|    std                  | 0.648        |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94           |\n",
      "|    ep_rew_mean          | -50.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 4967         |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037792837 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.98        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | 0.000719     |\n",
      "|    std                  | 0.642        |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete! Model saved as 'ppo_investment_agent_11-12_22-53'\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%d-%m_%H-%M\")\n",
    "\n",
    "# Create vectorised environment (runs multiple envs in parallel for faster training)\n",
    "env = make_vec_env(InvestmentEnv, n_envs=4)\n",
    "\n",
    "# Create evaluation environment (for monitoring progress)\n",
    "eval_env = InvestmentEnv()\n",
    "\n",
    "# Set up evaluation callback (checks performance during training)\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path='./logs/',\n",
    "    log_path='./logs/',\n",
    "    eval_freq=10000,  # Evaluate every 10k steps\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    "    n_eval_episodes=100  # Run 100 episodes for evaluation\n",
    ")\n",
    "\n",
    "# Initialise PPO agent\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    ent_coef=0.01,  # Encourages exploration - fixes \"sparse reward + poor exploration problem\"\n",
    "    tensorboard_log=\"./ppo_investment_tensorboard/\"\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(\n",
    "    total_timesteps=500000,  # Total training steps (adjust if needed)\n",
    "    callback=eval_callback,\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(f\"ppo_investment_agent_{timestamp}\")\n",
    "print(f\"\\nTraining complete! Model saved as 'ppo_investment_agent_{timestamp}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70aedb",
   "metadata": {},
   "source": [
    "## RL Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = PPO.load(\"ppo_investment_agent_11-12_21-49.zip\")\n",
    "\n",
    "# Test the agent\n",
    "def evaluate_agent(model, num_episodes=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Run the trained agent for multiple episodes and collect results.\n",
    "    \"\"\"\n",
    "    env = InvestmentEnv()\n",
    "    final_capitals = []\n",
    "    bankruptcies = 0\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset(seed=seed + episode)\n",
    "        episode_capital = []\n",
    "        \n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            # Agent chooses action\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_capital.append(info['capital'])\n",
    "        \n",
    "        final_capital = info['capital']\n",
    "        final_capitals.append(final_capital)\n",
    "        \n",
    "        if final_capital == 0:\n",
    "            bankruptcies += 1\n",
    "    \n",
    "    return np.array(final_capitals), bankruptcies\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Evaluating trained agent...\")\n",
    "rl_capitals, rl_bankruptcies = evaluate_agent(model, num_episodes=10000)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RL AGENT PERFORMANCE (10,000 episodes)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean final capital: ${rl_capitals.mean():,.2f}\")\n",
    "print(f\"Median final capital: ${np.median(rl_capitals):,.2f}\")\n",
    "print(f\"Std deviation: ${rl_capitals.std():,.2f}\")\n",
    "print(f\"Min: ${rl_capitals.min():,.2f}\")\n",
    "print(f\"Max: ${rl_capitals.max():,.2f}\")\n",
    "print(f\"Bankruptcies: {rl_bankruptcies} ({rl_bankruptcies/100:.1f}%)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9787379",
   "metadata": {},
   "source": [
    "## Static vs Dynamic Strategy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fixed_strategy(percentage, num_episodes=10000, seed=42):\n",
    "    \"\"\"\n",
    "    Test a fixed investment percentage strategy.\n",
    "    \"\"\"\n",
    "    env = InvestmentEnv()\n",
    "    final_capitals = []\n",
    "    bankruptcies = 0\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset(seed=seed + episode)\n",
    "        \n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            action = np.array([percentage])  # Fixed percentage\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        final_capital = info['capital']\n",
    "        final_capitals.append(final_capital)\n",
    "        \n",
    "        if final_capital == 0:\n",
    "            bankruptcies += 1\n",
    "    \n",
    "    return np.array(final_capitals), bankruptcies\n",
    "\n",
    "\n",
    "# Test fixed 20% strategy\n",
    "print(\"\\nEvaluating fixed 20% strategy...\")\n",
    "fixed_capitals, fixed_bankruptcies = evaluate_fixed_strategy(0.20, num_episodes=10000)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FIXED 20% STRATEGY PERFORMANCE (10,000 episodes)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean final capital: ${fixed_capitals.mean():,.2f}\")\n",
    "print(f\"Median final capital: ${np.median(fixed_capitals):,.2f}\")\n",
    "print(f\"Std deviation: ${fixed_capitals.std():,.2f}\")\n",
    "print(f\"Min: ${fixed_capitals.min():,.2f}\")\n",
    "print(f\"Max: ${fixed_capitals.max():,.2f}\")\n",
    "print(f\"Bankruptcies: {fixed_bankruptcies} ({fixed_bankruptcies/100:.1f}%)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RL Agent median: ${np.median(rl_capitals):,.2f}\")\n",
    "print(f\"Fixed 20% median: ${np.median(fixed_capitals):,.2f}\")\n",
    "print(f\"Improvement: {((np.median(rl_capitals) / np.median(fixed_capitals)) - 1) * 100:.1f}%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba64b08",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_agent_strategy(model, num_episodes=100):\n",
    "    \"\"\"\n",
    "    Analyse how investment percentage varies by round number.\n",
    "    \"\"\"\n",
    "    env = InvestmentEnv()\n",
    "    investment_data = {round_num: [] for round_num in range(100)}\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset(seed=42 + episode)\n",
    "        \n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            current_round = int(obs[1])\n",
    "            investment_pct = action[0]\n",
    "            \n",
    "            investment_data[current_round].append(investment_pct * 100)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    # Calculate mean investment per round\n",
    "    rounds = []\n",
    "    mean_investments = []\n",
    "    \n",
    "    for round_num in range(100):\n",
    "        if investment_data[round_num]:\n",
    "            rounds.append(round_num)\n",
    "            mean_investments.append(np.mean(investment_data[round_num]))\n",
    "    \n",
    "    return rounds, mean_investments\n",
    "\n",
    "\n",
    "# Analyse and plot\n",
    "rounds, mean_investments = analyse_agent_strategy(model, num_episodes=500)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rounds, mean_investments, linewidth=2)\n",
    "plt.xlabel('Round Number', fontsize=12)\n",
    "plt.ylabel('Mean Investment Percentage (%)', fontsize=12)\n",
    "plt.title('RL Agent Investment Strategy Across Rounds', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=20, color='r', linestyle='--', label='Fixed 20% Strategy', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
